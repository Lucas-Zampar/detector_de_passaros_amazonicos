{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b2b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from fiftyone import ViewField as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caafe52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc878ae",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fo.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4274e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'faster_rcnn_backbone_selection_model_4'\n",
    "\n",
    "#dataset_name = 'faster_rcnn_hyperparameter_tuning_model_14'\n",
    "\n",
    "#dataset_name = 'faster_rcnn_final_test_model_0'\n",
    "\n",
    "dataset = fo.load_dataset(dataset_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c6b76",
   "metadata": {},
   "source": [
    "# Interactive Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d5a25ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |█████████████████| 282/282 [768.2ms elapsed, 0s remaining, 367.1 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "cm = dataset.evaluate_detections(\n",
    "     pred_field = \"prediction\",\n",
    "     gt_field = \"ground_truth\",\n",
    "     classwise= False,\n",
    "     eval_key = 'eval_cm'\n",
    ")\n",
    "\n",
    "#plot = cm.plot_confusion_matrix()\n",
    "#plot.show(height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c79c43",
   "metadata": {},
   "source": [
    "# Launch App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f90a4c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?context=ipython&subscription=1a423d4c-a756-4c0c-8e2b-9e3ca6afda75\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdf0b248520>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset:          faster_rcnn_backbone_selection_model_4\n",
       "Media type:       image\n",
       "Num samples:      6\n",
       "Selected samples: 0\n",
       "Selected labels:  0\n",
       "Session URL:      http://localhost:5151/\n",
       "View stages:\n",
       "    1. Match(filter={'$expr': {'$gt': [...]}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#match = F(\"eval\") == \"fp\" \n",
    "match = (F(\"eval\") == \"tp\" ) & (F(\"eval_cm\") == \"fp\" )\n",
    "\n",
    "\n",
    "view = dataset.match(\n",
    "    F(\"prediction.detections\").filter(match).length() > 0\n",
    ")\n",
    "\n",
    "session = fo.launch_app(view, port=5151)\n",
    "\n",
    "#session.plots.attach(plot)\n",
    "\n",
    "session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e7cf4",
   "metadata": {},
   "source": [
    "# Desenhar BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9733b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import floor, asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ee528b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_replace = {\n",
    "    'canario_do_amazonas':'canário-do-amazonas',\n",
    "    'sanhaco_da_amazonia': 'sanhaço-da-amazônia', \n",
    "    'sanhaco_do_coqueiro': 'sanhaço-do-coqueiro', \n",
    "    'chupim': 'chupim',  \n",
    "    'rolinha': 'rolinha',\n",
    "    \n",
    "}\n",
    "\n",
    "color_per_label = {\n",
    "    'canario_do_amazonas':'#ffc600', #amarelo\n",
    "    'sanhaco_da_amazonia': '#072ac8', #azul\n",
    "    'sanhaco_do_coqueiro':'#2b9348', #verde\n",
    "    'chupim': '#9e4347', #marrom\n",
    "    'rolinha':'#2d3752' #acizentado    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e5211bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bounding_box(bounding_box, image_height= 1280, image_width = 720):\n",
    "    \n",
    "    relative_top_left_x = bounding_box[0]\n",
    "    relative_top_left_y = bounding_box[1]\n",
    "    \n",
    "    relative_width = bounding_box[2]\n",
    "    relative_height = bounding_box[3]\n",
    "        \n",
    "    top_left_x = floor(image_height * relative_top_left_x)\n",
    "    top_left_y = floor(image_width * relative_top_left_y)\n",
    "    \n",
    "    width = floor(image_height * relative_width)\n",
    "    height =  floor(image_width * relative_height)   \n",
    "    \n",
    "    bottom_right_x = top_left_x + width\n",
    "    bottom_right_y = top_left_y + height\n",
    "    \n",
    "    return (int(top_left_x) , int(top_left_y)), (int(bottom_right_x), int(bottom_right_y)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "064a548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = F(\"eval\") == \"fp\" \n",
    "\n",
    "view = dataset.match(\n",
    "    F(\"prediction.detections\").filter(match).length() > 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b142d0",
   "metadata": {},
   "source": [
    "## Desenhar BB com PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6c61c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "afbedbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bb(detection, editable_image, example=False):\n",
    "    label = detection['label']    \n",
    "    bounding_box = detection['bounding_box']\n",
    "    #confidence = detection['confidence']\n",
    "\n",
    "    color = color_per_label[label]\n",
    "\n",
    "    start_point_bb, end_point_bb = convert_bounding_box(bounding_box)\n",
    "\n",
    "\n",
    "    start_point_rect = start_point_bb[0], start_point_bb[1]-40\n",
    "    end_point_rect = start_point_bb[0]+150, start_point_bb[1]\n",
    "\n",
    "    start_point_text = start_point_bb[0]+20, start_point_bb[1]-35\n",
    "\n",
    "\n",
    "    editable_image.rectangle((start_point_bb, end_point_bb), None, color, bb_width)\n",
    "    if not example:\n",
    "        editable_image.rectangle((start_point_rect, end_point_rect), color, color, bb_width)\n",
    "        editable_image.text(start_point_text, f'{confidence:.2%}', (255,255,255), font=font)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ca03b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_width = 7\n",
    "eval_type = 'eval'\n",
    "eval_value = 'fp'\n",
    "output = 'notebooks/mistakes/{}.png'\n",
    "\n",
    "font = ImageFont.truetype('arial.ttf', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "967c8260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sample in view: \n",
    "    filepath = sample['filepath']\n",
    "    image = Image.open(filepath)\n",
    "    editable_image = ImageDraw.Draw(image)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for detection in sample['prediction']['detections']:\n",
    "    \n",
    "        if detection[eval_type] == eval_value:\n",
    "            draw_bb(detection, editable_image)\n",
    "            count += 1            \n",
    "            \n",
    "    if count >  0: \n",
    "        image = editable_image._image\n",
    "        image_name = sample['id'] + '.png'\n",
    "        image.save(image_name)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b338d08",
   "metadata": {},
   "source": [
    "### Para os TPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22e7a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basepath = 'mistakes/backbone_selection/TP/'\n",
    "#basepath = 'mistakes/hyperparameter_tunning/TP/'\n",
    "#basepath = 'mistakes/final_test/'\n",
    "#basepath = 'mistakes/final_test/TP/'\n",
    "\n",
    "tp_file = open(basepath+'tp.txt', 'r')\n",
    "detection_id = [detection_id.strip() for detection_id in tp_file.readlines()]\n",
    "\n",
    "for sample in view: \n",
    "    filepath = sample['filepath']\n",
    "    image = Image.open(filepath)\n",
    "    editable_image = ImageDraw.Draw(image)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for detection in sample['prediction']['detections']:\n",
    "    \n",
    "        if detection['id'] in detection_id:\n",
    "            draw_bb(detection, editable_image)\n",
    "            count += 1            \n",
    "            \n",
    "    if count >  0: \n",
    "        image = editable_image._image\n",
    "        image_name = sample['id'] + '.png'\n",
    "        image.save(image_name)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60e7602e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['63e20a8c8c6cff70052c7924',\n",
       " '63e20a8c8c6cff70052c7922',\n",
       " '63e20a8c8c6cff70052c795d',\n",
       " '63e20a8d8c6cff70052c7a27',\n",
       " '']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_id "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5abbe03",
   "metadata": {},
   "source": [
    "### Para o exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a7997f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = '63dd501af7b01e85c8a92233'\n",
    "gt = ['63dd5018f7b01e85c8a920d0','63dd5018f7b01e85c8a920cf']\n",
    "dt = ['63dd5018f7b01e85c8a920d3', '63dd5018f7b01e85c8a920d2', '63dd5018f7b01e85c8a920d1']\n",
    "\n",
    "sample = view[sample_id]\n",
    "filepath = sample['filepath']\n",
    "\n",
    "image = Image.open(filepath)\n",
    "detections = sample['ground_truth']['detections']\n",
    "\n",
    "for detection in detections: \n",
    "    editable_image = ImageDraw.Draw(image)\n",
    "    draw_bb(detection, editable_image)\n",
    "    \n",
    "image = editable_image._image\n",
    "image_name = sample['id'] + '.png'\n",
    "image.save(image_name)\n",
    "\n",
    "\n",
    "detections = sample['prediction']['detections']\n",
    "\n",
    "# for detection in detections: \n",
    "#     image = Image.open(filepath)\n",
    "#     editable_image = ImageDraw.Draw(image)\n",
    "#     editable_image = draw_bb(detection, editable_image)\n",
    "#     image = editable_image._image\n",
    "#     image_name = sample[_] + '.png'\n",
    "#     image.save(image_name)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a5c0fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = sample['ground_truth']['detections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85a6818d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Detection: {\n",
       "     'id': '63dd5018f7b01e85c8a920cf',\n",
       "     'attributes': {},\n",
       "     'tags': [],\n",
       "     'label': 'sanhaco_do_coqueiro',\n",
       "     'bounding_box': [\n",
       "         0.59921875,\n",
       "         0.08333333333333333,\n",
       "         0.12734375,\n",
       "         0.24305555555555555,\n",
       "     ],\n",
       "     'mask': None,\n",
       "     'confidence': None,\n",
       "     'index': None,\n",
       "     'eval': 'tp',\n",
       "     'eval_id': '63dd5018f7b01e85c8a920d3',\n",
       "     'eval_iou': 0.82195802142962,\n",
       "     'eval_cm': 'fn',\n",
       "     'eval_cm_id': '63dd5018f7b01e85c8a920d2',\n",
       "     'eval_cm_iou': 0.8578947368421053,\n",
       " }>,\n",
       " <Detection: {\n",
       "     'id': '63dd5018f7b01e85c8a920d0',\n",
       "     'attributes': {},\n",
       "     'tags': [],\n",
       "     'label': 'sanhaco_do_coqueiro',\n",
       "     'bounding_box': [0.775, 0.37777777777777777, 0.225, 0.2847222222222222],\n",
       "     'mask': None,\n",
       "     'confidence': None,\n",
       "     'index': None,\n",
       "     'eval': 'fn',\n",
       "     'eval_id': '',\n",
       "     'eval_cm': 'fn',\n",
       "     'eval_cm_id': '63dd5018f7b01e85c8a920d1',\n",
       "     'eval_cm_iou': 0.7206978319783196,\n",
       " }>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169ad91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e903d1d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Desenhar BB com OpenCV (Não recomendado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f8378",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# refiz trabalho a toa \n",
    "\n",
    "match = F(\"eval\") == \"tp\" \n",
    "\n",
    "view = dataset.match(\n",
    "    F(\"prediction.detections\").filter(match).length() > 0\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "bb_thickness = 6\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.6\n",
    "font_color = (255, 255, 255)\n",
    "font_thickness = 3\n",
    "line_type = cv2.LINE_AA\n",
    "\n",
    "def hex_to_rgb(hex_string):\n",
    "    return [ int(hex_string[i:i+2], 16) for i in (1,3,5)]\n",
    "\n",
    "\n",
    "def rgb_to_bgr(rgb_list):\n",
    "    return rgb_list[::-1]\n",
    "    \n",
    "#sample = view.first()\n",
    "#filepath = sample['filepath']\n",
    "#image = cv2.imread(filepath)\n",
    "\n",
    "for sample in view: \n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    filepath = sample['filepath']\n",
    "    image = cv2.imread(filepath)\n",
    "    \n",
    "    for detection in sample['prediction']['detections']:\n",
    "        if detection['eval'] == 'fp':        \n",
    "            label = detection['label']    \n",
    "            bounding_box = detection['bounding_box']\n",
    "            confidence = detection['confidence']\n",
    "\n",
    "            color_hex = color_per_label[label]        \n",
    "            color_rgb = hex_to_rgb(color)\n",
    "            color_bgr = rgb_to_bgr(rgb_code)\n",
    "\n",
    "            start_point, end_point = convert_bounding_box(bounding_box)\n",
    "\n",
    "            #text = '({:.2%})'.format(confidence)\n",
    "            text = label\n",
    "            text_position = start_point[0], start_point[1] - 10\n",
    "\n",
    "            text_rect_start_point =  start_point[0]-5, start_point[1] - 30\n",
    "            text_rect_end_point = end_point[0]+50, start_point[1] \n",
    "\n",
    "            print(text)\n",
    "            print(start_point, end_point)\n",
    "\n",
    "            cv2.rectangle(image, start_point, end_point, color_bgr, bb_thickness)\n",
    "            cv2.rectangle(image, text_rect_start_point, text_rect_end_point, color_bgr, -1)\n",
    "\n",
    "            count += 1\n",
    "            #cv2.putText(image,text,text_position,font, font_scale, font_color, font_thickness)\n",
    "    if count > 0: \n",
    "        im.\n",
    "        \n",
    "            \n",
    "            \n",
    "image = Image.fromarray(image[:,:,::-1])          \n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6410b92",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Desenhar BB com FiftyOne (Não recomendado) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed513a1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import fiftyone.utils.annotations as foua\n",
    "import eta.core.annotations as etaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678b78ae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#match = (F(\"eval\") == \"tp\") & (F(\"eval_cm\") == \"fp\")\n",
    "match = (F(\"eval_cm\") == \"fp\") \n",
    "\n",
    "view = dataset.match(\n",
    "    F(\"prediction.detections\").filter(match).length() > 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dafd4de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "session = fo.launch_app(view, port=5151)\n",
    "\n",
    "#session.plots.attach(plot)\n",
    "\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d497d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "label_to_replace = {\n",
    "    'canario_do_amazonas':'canário-do-amazonas',\n",
    "    'sanhaco_da_amazonia': 'sanhaço-da-amazônia', \n",
    "    'sanhaco_do_coqueiro': 'sanhaço-do-coqueiro', \n",
    "    'chupim': 'chupim',  \n",
    "    'rolinha': 'rolinha',\n",
    "    \n",
    "}\n",
    "\n",
    "color_per_label = {\n",
    "    'canario_do_amazonas':'#ffc600', #amarelo\n",
    "    'sanhaco_da_amazonia': '#072ac8', #azul\n",
    "    'sanhaco_do_coqueiro':'#2b9348', #verde\n",
    "    'chupim': '#9e4347', #marrom\n",
    "    'rolinha':'#2d3752' #acizentado    \n",
    "}\n",
    "\n",
    "\n",
    "draw_config = foua.DrawConfig({\n",
    "        \"show_object_labels\": False,\n",
    "        \"show_all_confidences\": True,\n",
    "    \n",
    "        \"font_size\": 32,\n",
    "        \"bbox_linewidth\": 6,\n",
    "    \n",
    "        \"bbox_alpha\": 1.00, \n",
    "        \n",
    "        \"per_object_label_colors\": True,\n",
    "        \n",
    "        \"show_object_names\": False,\n",
    "        \"show_object_attrs\": False,\n",
    "    })\n",
    "\n",
    "outputpath = 'mistakes/final_test/{}.png'\n",
    "\n",
    "i=0\n",
    "\n",
    "#for sample in dataset:\n",
    "for sample in view:\n",
    "\n",
    "    detection_list = []\n",
    "    #color_list = []\n",
    "    \n",
    "    filepath = sample['filepath']\n",
    "    \n",
    "    for detection in sample['prediction']['detections']:\n",
    "            if detection['eval'] == 'fp':\n",
    "                \n",
    "\n",
    "                label = detection['label'] # classe da detecção \n",
    "                replaced_label = label_to_replace[label] # substituía por nome mais amigável\n",
    "                bounding_box = detection['bounding_box'] # coordenadas relativas das detecções [x0,y0,width,height]\n",
    "                confidence = detection['confidence'] # nível de confiança da detecção\n",
    "\n",
    "                # adiciona detecção a lista de detecções\n",
    "                detection_list.append(\n",
    "                    fo.Detection(\n",
    "                        label = replaced_label, \n",
    "                        bounding_box = bounding_box, \n",
    "                        confidence = confidence\n",
    "                    )\n",
    "                )\n",
    "                color = color_per_label[label]\n",
    "    \n",
    "            #if not color in color_list:\n",
    "            #   color_list.append(color)\n",
    "\n",
    "    \n",
    "    color_list = [color_per_label[label]]\n",
    "    #color_list = color_list\n",
    "    \n",
    "    i+=1        \n",
    "\n",
    "    # a cor das detecções [restrito a uma única classe]\n",
    "    colormap_config = etaa.ColormapConfig({\n",
    "        \"type\": \"eta.core.annotations.ManualColormap\",\n",
    "        \"config\": {\"colors\": color_list}})\n",
    "    \n",
    "    # caminho de saída\n",
    "    \n",
    "    detections = fo.Detections(detections=detection_list)\n",
    "    new_sample = fo.Sample(filepath, pred_objects=detections)\n",
    "    foua.draw_labeled_image(new_sample, outputpath.format(i), config=draw_config, colormap_config=colormap_config)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32966494",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "# Desenho manual para o último modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524829e8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "match = F(\"eval\") == \"fp\"\n",
    "\n",
    "view = dataset.match(\n",
    "    F(\"prediction.detections\").filter(match).length() > 0\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# casos específicos do final apenas\n",
    "\n",
    "# confusão\n",
    "\n",
    "sc_cp = '63e20a8c8c6cff70052c7924' \n",
    "sc_cp2 = '63e20a8d8c6cff70052c79c4'\n",
    "sc_sa = '63e20a8c8c6cff70052c7922'\n",
    "cp_ca = '63e20a8c8c6cff70052c795d'\n",
    "cp_sc = '63e20a8d8c6cff70052c7a27'\n",
    "\n",
    "\n",
    "# correto \n",
    "\n",
    "sc_sc = '63e20a8c8c6cff70052c7921'\n",
    "cp_cp = '63e20a8c8c6cff70052c795f'\n",
    "cp_cp2 = '63e20a8d8c6cff70052c7a29'\n",
    "\n",
    "\n",
    "confusion = ['63e20a8c8c6cff70052c7924', '63e20a8d8c6cff70052c79c4', '63e20a8c8c6cff70052c7922', '63e20a8c8c6cff70052c795d',  '63e20a8d8c6cff70052c7a27']\n",
    "correct = ['63e20a8c8c6cff70052c7921', '63e20a8c8c6cff70052c795f', '63e20a8d8c6cff70052c7a29']\n",
    "\n",
    "outputpath = 'mistakes/final_test/{}.png'\n",
    "\n",
    "i =0 \n",
    "\n",
    "for sample in view: \n",
    "    \n",
    "    filepath = sample['filepath']\n",
    "    \n",
    "    for detection in sample['prediction']['detections']:\n",
    "        \n",
    "        if detection['id'] in confusion:\n",
    "            \n",
    "                label = detection['label'] # classe da detecção \n",
    "                replaced_label = label_to_replace[label] # substituía por nome mais amigável\n",
    "                bounding_box = detection['bounding_box'] # coordenadas relativas das detecções [x0,y0,width,height]\n",
    "                confidence = detection['confidence'] # nível de confiança da detecção\n",
    "                \n",
    "                detections = fo.Detections(detections=[\n",
    "                      fo.Detection(\n",
    "                        label = replaced_label, \n",
    "                        bounding_box = bounding_box, \n",
    "                        confidence = confidence\n",
    "                    )  \n",
    "                ])\n",
    "                            \n",
    "                new_sample = fo.Sample(filepath, pred_objects=detections)\n",
    "                \n",
    "                color_list = [color_per_label[label]]\n",
    "                colormap_config = etaa.ColormapConfig({\n",
    "                    \"type\": \"eta.core.annotations.ManualColormap\",\n",
    "                    \"config\": {\"colors\": color_list}})\n",
    "                \n",
    "                foua.draw_labeled_image(new_sample, outputpath.format(i), config=draw_config, colormap_config=colormap_config)\n",
    "                i+=1\n",
    "\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a050a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32819ac",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab6c86",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c4cf7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf4fbfa1",
   "metadata": {},
   "source": [
    "# Count Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6227c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usado para gerar os arquivos de proporção de anotação\n",
    "# import pandas as pd\n",
    "# total_labels = dataset.count_values(\"ground_truth.detections.label\")\n",
    "\n",
    "# df = pd.DataFrame(total_labels, columns=sorted(total_labels), index=[0])\n",
    "# df.to_csv('complete_valid_proportion.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4d552",
   "metadata": {},
   "source": [
    "# Compute PR curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13554674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs an IoU sweep so that mAP and PR curves can be computed\n",
    "\n",
    "# results_5 = eval_fo_dataset(dataset, compute_mAP=True, iou_threshs = [.5])\n",
    "# plot = results_5.plot_pr_curves(classes=results_5.classes)\n",
    "# plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_per_class = results_5.report(classes=results_5.classes)\n",
    "\n",
    "# transforma dicionário em dataframe \n",
    "# metrics_per_class = pd.DataFrame(metrics_per_class)\n",
    "# metrics_per_class = metrics_per_class.T\n",
    "# metrics_per_class = metrics_per_class.drop(['support'], axis=1)\n",
    "# metrics_per_class = metrics_per_class.drop(['micro avg', 'macro avg', 'weighted avg'], axis=0)\n",
    "# display(metrics_per_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daff9c9",
   "metadata": {},
   "source": [
    "# Transform BB in absolute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b0856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for detection in dataset['63c97040bcee5f9d5baf5a79'].ground_truth.detections:\n",
    "# from math import floor\n",
    "\n",
    "# dataset['63c97040bcee5f9d5baf5a79'].prediction.detections\n",
    "\n",
    "# for detection in dataset['63c97040bcee5f9d5baf5a79'].prediction.detections:\n",
    "#     print(detection['label'],'-',detection['confidence'])\n",
    "    \n",
    "#     width = floor(1280*detection['bounding_box'][2])\n",
    "#     height =  floor(720*detection['bounding_box'][3])   \n",
    "    \n",
    "#     top_left_x = floor(detection['bounding_box'][0] * 1280 )\n",
    "#     top_left_y = floor(detection['bounding_box'][1] * 720 )\n",
    "    \n",
    "    \n",
    "#     print('X: {} - Y: {}'.format(top_left_x, top_left_y))\n",
    "#     print('W: {} - H: {}'.format(width, height))\n",
    "#     print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818503d",
   "metadata": {},
   "source": [
    "# Computa IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82beb896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_id = '63c97040bcee5f9d5baf5af9'\n",
    "# sample = matching_view[sample_id]\n",
    "\n",
    "\n",
    "# sample_gts = sample['ground_truth']['detections']\n",
    "# sample_preds = sample['prediction']['detections']\n",
    "\n",
    "# gt_ids = ['63c9703fbcee5f9d5baf59aa', '63c9703fbcee5f9d5baf59a9']\n",
    "# pred_ids = ['63c9703fbcee5f9d5baf59af']\n",
    "\n",
    "\n",
    "\n",
    "# gts = [detection for detection in sample_gts if detection['id'] in gt_ids] \n",
    "# preds = [detection for detection in sample_preds if detection['id'] in pred_ids] \n",
    "\n",
    "\n",
    "# fo.utils.iou.compute_ious(preds, gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf398b",
   "metadata": {},
   "source": [
    "# Teste para entender o critério de decisão da matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = dataset['63c97040bcee5f9d5baf5a79']\n",
    "\n",
    "# sample['prediction']['detections'][1]['label'] = 'Sanhaço do Coqueiro'\n",
    "# sample['prediction']['detections'][1]['confidence'] = 0.30\n",
    "\n",
    "# sample['prediction']['detections'][2]['label'] = 'Sanhaço do Coqueiro'\n",
    "# sample['prediction']['detections'][2]['confidence'] = 0.90\n",
    "\n",
    "# sample.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
